---
layout: post
title:  "WaveNet Review"
author: seujung
date:   2018-06-02 20:21:48
tags:	[deep-learning,paper]
image: /files/covers/sound-cover.jpg
---

#### 논문 개요
딥마인드에서 오디오 시그널에 대한 모델로 제시한 network 입니다. 해당 논문이 가지는 가장 큰 장점은 오디오의 waveform 자체 데이터를 활용해서 모델링을 수행한 점입니다. 또한 이를 통해 생성한 TTS는 기존의 결과보다 많이 나은 성능을 보여주고 있습니다. 최근에는 Google Home에 해당 네트워크가 탑제되었으며 wav 파일 관련해서 reference network로 많이 활용되고 있습니다.
[Paper](https://arxiv.org/pdf/1609.03499.pdf)
[Deepmind blog](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)

#### Network Architecture 설명
네트워크를 이해하기 위해서는 해당 내용에 대한 개념을 먼저 이해해야 합니다.
- stack of dilated casual convolution
- Residual and skip connection
- softmax distribution


#### stack of dilated casual convolution
우선 WAV 데이터 형태는 1차원의 데이터 형태이기 때문에 CNN 적용 시 Conv1D 를 기본적으로 활용하고 있습니다. 해당 네트워크 구조를 이해하기 위해서는 우선적으로 dilation 개념에 대한 이해가 먼저 필요 합니다.
dilation의 의미는 CNN 수행 시 커널을 구성함에 있어서 커널의 Pixel 사이에 얼마나 빈 공간을 줄 것인가 하는 점입니다. 기본적으로 사용하는 커널은 dilation=1 이며 dilation 값이 추가 될 수록 커널 사이에 빈 공간이 추가 된다고 보시면 됩니다.
![Fig 1. Dilation=2 인 경우](/files/180602_wavenet/dilation.gif)

WaveNet에서 사용하는 stacked of dilated casual convolution의 경우 1D Conv를 누적으로 쌓는 형태를 기본으로 한 후 누적 시 마다 dilation의 값을 2의 배수 만큼 증가시키는 형태압니다. 이 때 사용하는 parameter가 depth 값이며 만약 depth =10 이면 1, 2, 4, 8, 16 ,..., 512  순서로 stack 작업을 수행합니다.
![Fig 2. depth=10 경우](/files/180602_wavenet/fig2.png)


#### Residual and Skip connections
Input Data(x)가 네트워크로 들어오면 다음의 Process 과정을 거칩니다.
1. tanh(x), sigmoid(x), skip_connection(x) 의 3가지 network path을 설정
2. 3가지 path에 대해 Dilated Conv를 적용
3. tanh와 sigmoid의 경우에는 Gate Activation Unit 방법을 적용

 $$ z = tanh(W_{f,k} * x) \odot \sigma(W_{g,k} * x) $$ 

4. 3의 결과에 1X1 Conv 적용
5. 4의 결과와 Input Data(x)와 resudial 적용
6. 5의 결과와 skip_connection(x)와 sum 적용
7. 6의 결과에 대해 Relu - 1X1 Conv -Relu - 1X1 Conv - Softmax 를 적용하여 최종 Output을 산출
![Fig 3. Residual & Skip Connection](/files/180602_wavenet/fig3.png)

#### Softmax Disribution
WaveNet 적용 시 output class는 Audio의 timestep 별 integer 값 입니다. 하지만 이 값이 상당히 많은 range 값을 가지고 있습니다.(16bit의 경우에 65,534(2의 16제곱) 값을 가짐) 따라서 Output class 의 범위를 좁히는 과정이 필요한데 이 때 사용하는 방법이 $\mu$ -law companding transformation 입니다. 해당 방법을 적용하면 우리가 설정한 $\mu$ 값으로 class 범위를 줄일 수 있습니다.

$$ f(x_{t}) = sign(x_{t})\frac {ln(1+\mu|x_{t}|)}{ln(1+\mu)} $$

##### Reference
[WaveNet](https://arxiv.org/pdf/1609.03499.pdf)
[https://kionkim.github.io/2018/06/08/Convolution_arithmetic/](https://kionkim.github.io/2018/06/08/Convolution_arithmetic/)

